{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lDe9CkE624g"
      },
      "source": [
        "### Entendimiento de los datos y EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "hgjobfXM68JS",
        "outputId": "bfbf5a45-19a1-4ad7-9659-da032b82a777"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train = pd.read_csv(\"sales_train.csv\")\n",
        "test  = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train.columns = train.columns.str.strip()\n",
        "test.columns  = test.columns.str.strip()\n",
        "\n",
        "print(\"train shape:\", train.shape)\n",
        "print(\"test  shape:\", test.shape)\n",
        "\n",
        "display(train.head())\n",
        "display(test.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_TbpU9zh688T",
        "outputId": "8bd4fd1b-1233-4821-d026-b723560b375c"
      },
      "outputs": [],
      "source": [
        "data_dict = pd.DataFrame({\n",
        "    \"col\": train.columns,\n",
        "    \"meaning\": [\n",
        "        \"Fecha (día) de la transacción\",\n",
        "        \"Índice de mes (0 = primer mes del dataset, 1 = segundo, ...)\",\n",
        "        \"ID de tienda/sucursal\",\n",
        "        \"ID de producto\",\n",
        "        \"Precio observado del producto en esa transacción\",\n",
        "        \"Unidades vendidas ese día (puede ser negativa por devoluciones)\"\n",
        "    ]\n",
        "})\n",
        "display(data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "LSggLvDf7vn3",
        "outputId": "860bb7a3-781c-4d83-c9b5-cc12a5b5f042"
      },
      "outputs": [],
      "source": [
        "print(train.info())\n",
        "\n",
        "nulls = (train.isna().mean().sort_values(ascending=False) * 100).to_frame(\"% null\")\n",
        "display(nulls)\n",
        "\n",
        "nulls_test = (test.isna().mean().sort_values(ascending=False) * 100).to_frame(\"% null\")\n",
        "display(nulls_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "OkfMs7K_71td",
        "outputId": "ec4f4e09-4a91-4e0b-e030-f548af2c3a8f"
      },
      "outputs": [],
      "source": [
        "# Convertibles a numérico (sin modificar aún, solo para revisar)\n",
        "num_cols = [\"date_block_num\",\"shop_id\",\"item_id\",\"item_price\",\"item_cnt_day\"]\n",
        "tmp = train[num_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "print(\"min/max:\")\n",
        "display(pd.DataFrame({\"min\": tmp.min(), \"max\": tmp.max(), \"n_nan\": tmp.isna().sum()}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3nXArJCi8LL0",
        "outputId": "f3df5b3f-2423-46b9-eb46-227419d51baa"
      },
      "outputs": [],
      "source": [
        "tmp = train.copy()\n",
        "tmp[\"item_price\"] = pd.to_numeric(tmp[\"item_price\"], errors=\"coerce\")\n",
        "tmp[\"item_cnt_day\"] = pd.to_numeric(tmp[\"item_cnt_day\"], errors=\"coerce\")\n",
        "\n",
        "# Precio (raw + zoom p99)\n",
        "p = tmp[\"item_price\"].dropna()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(p, bins=100)\n",
        "plt.title(\"item_price (raw)\")\n",
        "plt.xlabel(\"item_price\")\n",
        "plt.ylabel(\"freq\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(p.clip(upper=p.quantile(0.99)), bins=100)\n",
        "plt.title(\"item_price (clip p99)\")\n",
        "plt.xlabel(\"item_price (clip)\")\n",
        "plt.ylabel(\"freq\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Cantidad diaria (zoom)\n",
        "c = tmp[\"item_cnt_day\"].dropna()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(c.clip(-5, 20), bins=80)\n",
        "plt.title(\"item_cnt_day (clip [-5,20])\")\n",
        "plt.xlabel(\"item_cnt_day\")\n",
        "plt.ylabel(\"freq\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Proporción devoluciones (item_cnt_day < 0):\", (c < 0).mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "9RJVd9wJ8pBg",
        "outputId": "a3b297cb-4698-4344-b271-f67168bf2f8a"
      },
      "outputs": [],
      "source": [
        "tmp = train.copy()\n",
        "tmp[\"date\"] = pd.to_datetime(tmp[\"date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
        "\n",
        "print(\"date range:\", tmp[\"date\"].min(), \"->\", tmp[\"date\"].max())\n",
        "print(\"date_block_num range:\", tmp[\"date_block_num\"].min(), \"->\", tmp[\"date_block_num\"].max())\n",
        "print(\"n meses distintos:\", tmp[\"date_block_num\"].nunique())\n",
        "\n",
        "# filas por mes (diario)\n",
        "m_rows = tmp.groupby(\"date_block_num\").size()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(m_rows.index, m_rows.values, marker=\"o\", linewidth=1)\n",
        "plt.title(\"Número de filas (transacciones) por mes - train diario\")\n",
        "plt.xlabel(\"date_block_num\")\n",
        "plt.ylabel(\"rows\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "H-4q7yBM9bW3",
        "outputId": "20c6b294-eff9-4559-952f-c626703dbdc4"
      },
      "outputs": [],
      "source": [
        "tmp = train.copy()\n",
        "tmp[\"item_cnt_day\"] = pd.to_numeric(tmp[\"item_cnt_day\"], errors=\"coerce\").fillna(0)\n",
        "tmp[\"item_price\"]   = pd.to_numeric(tmp[\"item_price\"], errors=\"coerce\")\n",
        "\n",
        "monthly = (\n",
        "    tmp.groupby([\"date_block_num\",\"shop_id\",\"item_id\"], as_index=False)\n",
        "       .agg(item_cnt_month=(\"item_cnt_day\",\"sum\"),\n",
        "            price_mean=(\"item_price\",\"mean\"))\n",
        ")\n",
        "\n",
        "# target mensual (como se evalúa)\n",
        "monthly[\"item_cnt_month_clip\"] = monthly[\"item_cnt_month\"].clip(0, 20)\n",
        "\n",
        "print(\"monthly shape:\", monthly.shape)\n",
        "display(monthly.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "f7OC9W-490Zh",
        "outputId": "b8716763-30af-48b5-8f5a-27154dcfb36d"
      },
      "outputs": [],
      "source": [
        "m_units = monthly.groupby(\"date_block_num\")[\"item_cnt_month_clip\"].sum()\n",
        "m_pairs = monthly.groupby(\"date_block_num\").size()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(m_units.index, m_units.values, marker=\"o\", linewidth=1)\n",
        "plt.title(\"Unidades totales por mes (suma de item_cnt_month_clip)\")\n",
        "plt.xlabel(\"date_block_num\")\n",
        "plt.ylabel(\"unidades\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(m_pairs.index, m_pairs.values, marker=\"o\", linewidth=1)\n",
        "plt.title(\"Actividad por mes (# pares shop-item con registro)\")\n",
        "plt.xlabel(\"date_block_num\")\n",
        "plt.ylabel(\"# pares\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "ykGPvpsW9-Q4",
        "outputId": "1660deb1-0945-4698-a87c-6545b2c5b70a"
      },
      "outputs": [],
      "source": [
        "y = monthly[\"item_cnt_month_clip\"]\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(y, bins=50)\n",
        "plt.title(\"Distribución de item_cnt_month_clip (0..20)\")\n",
        "plt.xlabel(\"item_cnt_month_clip\")\n",
        "plt.ylabel(\"freq\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Proporción de ceros (en monthly observado):\", (y == 0).mean())\n",
        "\n",
        "# Cuántos pares aparecen en total\n",
        "n_pairs_total = monthly[[\"shop_id\",\"item_id\"]].drop_duplicates().shape[0]\n",
        "print(\"Pares únicos (shop,item) observados en train:\", n_pairs_total)\n",
        "print(\"Pares únicos en test:\", test[[\"shop_id\",\"item_id\"]].drop_duplicates().shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "z-bLrh5d_3I2",
        "outputId": "ea09a8ae-9b79-44d3-b30f-5715eee29bcf"
      },
      "outputs": [],
      "source": [
        "monthly[\"month\"] = (monthly[\"date_block_num\"] % 12).astype(int)\n",
        "monthly[\"year\"]  = (monthly[\"date_block_num\"] // 12).astype(int)\n",
        "\n",
        "# Opción 1: estacionalidad en unidades totales por (año, mes)\n",
        "season = monthly.groupby([\"year\",\"month\"])[\"item_cnt_month_clip\"].sum().unstack(\"month\").fillna(0)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.imshow(season.values, aspect=\"auto\")\n",
        "plt.title(\"Estacionalidad: unidades totales por Año × Mes\")\n",
        "plt.xlabel(\"Mes (0=Ene)\")\n",
        "plt.ylabel(\"Año (index)\")\n",
        "plt.xticks(range(12), range(12))\n",
        "plt.yticks(range(len(season.index)), season.index)\n",
        "plt.colorbar(label=\"unidades\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Opción 2 (a veces mejor): promedio de ventas por par activo (normaliza actividad)\n",
        "season_mean = monthly.groupby([\"year\",\"month\"])[\"item_cnt_month_clip\"].mean().unstack(\"month\").fillna(0)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.imshow(season_mean.values, aspect=\"auto\")\n",
        "plt.title(\"Estacionalidad: promedio de item_cnt_month_clip por Año × Mes\")\n",
        "plt.xlabel(\"Mes (0=Ene)\")\n",
        "plt.ylabel(\"Año (index)\")\n",
        "plt.xticks(range(12), range(12))\n",
        "plt.yticks(range(len(season_mean.index)), season_mean.index)\n",
        "plt.colorbar(label=\"promedio por par\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WoK4mt8gAHqd",
        "outputId": "4758a7e7-48e0-4d94-b4ac-2b0b9e16e386"
      },
      "outputs": [],
      "source": [
        "# months con ventas (>0) por (shop,item)\n",
        "m2 = monthly.copy()\n",
        "m2[\"sold\"] = (m2[\"item_cnt_month_clip\"] > 0).astype(int)\n",
        "\n",
        "months_sold = (m2.groupby([\"shop_id\",\"item_id\"])[\"sold\"].sum())\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(months_sold, bins=40)\n",
        "plt.title(\"Intermitencia: #meses con venta (>0) por (shop,item)\")\n",
        "plt.xlabel(\"# meses con venta\")\n",
        "plt.ylabel(\"cantidad de pares\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Percentiles #meses con venta:\", months_sold.quantile([0.5,0.75,0.9,0.95,0.99]).to_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "dyMpJJZHC0SU",
        "outputId": "8a3ff850-1430-4170-b4f7-7f2e5d604ba3"
      },
      "outputs": [],
      "source": [
        "max_m = int(monthly[\"date_block_num\"].max())\n",
        "\n",
        "# último mes vendido por par (en todo train)\n",
        "last_sale = (monthly.loc[monthly[\"item_cnt_month_clip\"] > 0]\n",
        "                  .groupby([\"shop_id\",\"item_id\"])[\"date_block_num\"].max())\n",
        "\n",
        "# recency en el último mes observado\n",
        "recency = (max_m - last_sale).reindex(\n",
        "    monthly[[\"shop_id\",\"item_id\"]].drop_duplicates().set_index([\"shop_id\",\"item_id\"]).index\n",
        ")\n",
        "\n",
        "recency = recency.fillna(max_m + 1)  # nunca vendió -> muy grande\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(recency.clip(0, 24), bins=25)  # zoom\n",
        "plt.title(\"Recency: meses desde la última venta (zoom 0–24)\")\n",
        "plt.xlabel(\"meses desde última venta\")\n",
        "plt.ylabel(\"pares\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "P07mieT_C8FO",
        "outputId": "6d5232ea-3af5-4eb0-97c7-5703d0192973"
      },
      "outputs": [],
      "source": [
        "q = (monthly.groupby(\"date_block_num\")[\"item_cnt_month\"]\n",
        "            .quantile([0.5, 0.9, 0.99])\n",
        "            .unstack())\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(q.index, q[0.5], marker=\"o\", linewidth=1, label=\"p50\")\n",
        "plt.plot(q.index, q[0.9], marker=\"o\", linewidth=1, label=\"p90\")\n",
        "plt.plot(q.index, q[0.99], marker=\"o\", linewidth=1, label=\"p99\")\n",
        "plt.title(\"Percentiles de item_cnt_month por mes (antes de clip)\")\n",
        "plt.xlabel(\"date_block_num\")\n",
        "plt.ylabel(\"unidades\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "5ZJxjd_9DEMT",
        "outputId": "a97a938a-701f-41b4-c16b-e921e7f9c21e"
      },
      "outputs": [],
      "source": [
        "m3 = monthly.sort_values([\"shop_id\",\"item_id\",\"date_block_num\"]).copy()\n",
        "m3[\"lag1\"] = m3.groupby([\"shop_id\",\"item_id\"])[\"item_cnt_month_clip\"].shift(1)\n",
        "tmp = m3.dropna(subset=[\"lag1\"])\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(tmp[\"lag1\"].clip(0,5), tmp[\"item_cnt_month_clip\"].clip(0,5), s=4, alpha=0.15)\n",
        "plt.title(\"Relación: lag1 vs actual (zoom 0–5)\")\n",
        "plt.xlabel(\"lag1\")\n",
        "plt.ylabel(\"actual\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4-Ze8-5DM-U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJYwv2BISFRw"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngOoflOhSG7H",
        "outputId": "72640971-8b6a-4735-dccd-80108ecaded4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# =========================\n",
        "# 1) Cargar\n",
        "# =========================\n",
        "train = pd.read_csv(\"sales_train.csv\")\n",
        "test  = pd.read_csv(\"test.csv\")\n",
        "train.columns = train.columns.str.strip()\n",
        "test.columns  = test.columns.str.strip()\n",
        "\n",
        "# Tipos\n",
        "train[\"date_block_num\"] = pd.to_numeric(train[\"date_block_num\"], errors=\"coerce\")\n",
        "train[\"shop_id\"]        = pd.to_numeric(train[\"shop_id\"], errors=\"coerce\")\n",
        "train[\"item_id\"]        = pd.to_numeric(train[\"item_id\"], errors=\"coerce\")\n",
        "train[\"item_price\"]     = pd.to_numeric(train[\"item_price\"], errors=\"coerce\")\n",
        "train[\"item_cnt_day\"]   = pd.to_numeric(train[\"item_cnt_day\"], errors=\"coerce\")\n",
        "\n",
        "test[\"ID\"]      = pd.to_numeric(test[\"ID\"], errors=\"coerce\")\n",
        "test[\"shop_id\"] = pd.to_numeric(test[\"shop_id\"], errors=\"coerce\")\n",
        "test[\"item_id\"] = pd.to_numeric(test[\"item_id\"], errors=\"coerce\")\n",
        "\n",
        "train = train.dropna(subset=[\"date_block_num\",\"shop_id\",\"item_id\",\"item_price\",\"item_cnt_day\"])\n",
        "test  = test.dropna(subset=[\"ID\",\"shop_id\",\"item_id\"])\n",
        "\n",
        "# Cast compacto\n",
        "train[\"date_block_num\"] = train[\"date_block_num\"].astype(np.int16)\n",
        "train[\"shop_id\"] = train[\"shop_id\"].astype(np.int16)\n",
        "train[\"item_id\"] = train[\"item_id\"].astype(np.int16)\n",
        "test[\"ID\"] = test[\"ID\"].astype(np.int32)\n",
        "test[\"shop_id\"] = test[\"shop_id\"].astype(np.int16)\n",
        "test[\"item_id\"] = test[\"item_id\"].astype(np.int16)\n",
        "\n",
        "# =========================\n",
        "# 2) Tratamiento mínimo (valores especiales) para poder modelar\n",
        "#    (más “fino” lo harás en Notebook 2)\n",
        "# =========================\n",
        "# Precio negativo (p.ej. -1) -> inválido\n",
        "train = train[train[\"item_price\"] >= 0]\n",
        "\n",
        "# Outliers extremos (suave)\n",
        "train = train[train[\"item_price\"] < 100000]\n",
        "train = train[(train[\"item_cnt_day\"] > -1000) & (train[\"item_cnt_day\"] < 1000)]\n",
        "\n",
        "# =========================\n",
        "# 3) Agregación mensual\n",
        "# =========================\n",
        "monthly = (\n",
        "    train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"], as_index=False)\n",
        "         .agg(\n",
        "             item_cnt_month=(\"item_cnt_day\",\"sum\"),\n",
        "             price_mean=(\"item_price\",\"mean\"),\n",
        "         )\n",
        ")\n",
        "\n",
        "# clip target (tal como se suele hacer en esta comp)\n",
        "monthly[\"item_cnt_month\"] = monthly[\"item_cnt_month\"].clip(0, 20).astype(np.float32)\n",
        "monthly[\"price_mean\"] = monthly[\"price_mean\"].astype(np.float32)\n",
        "\n",
        "max_block  = int(monthly[\"date_block_num\"].max())  # debe ser 33\n",
        "test_block = max_block + 1                         # 34\n",
        "\n",
        "# =========================\n",
        "# 4) Agregados laggeados (global / item / shop)\n",
        "#    IMPORTANT: shift por +1 mes para evitar leakage\n",
        "# =========================\n",
        "global_agg = (\n",
        "    monthly.groupby(\"date_block_num\", as_index=False)\n",
        "           .agg(global_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                global_sum=(\"item_cnt_month\",\"sum\"),\n",
        "                global_pairs=(\"item_cnt_month\",\"size\"))\n",
        ")\n",
        "global_agg[\"date_block_num\"] = (global_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "item_agg = (\n",
        "    monthly.groupby([\"date_block_num\",\"item_id\"], as_index=False)\n",
        "           .agg(item_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                item_shops=(\"shop_id\",\"nunique\"),\n",
        "                item_price_mean=(\"price_mean\",\"mean\"))\n",
        ")\n",
        "item_agg[\"date_block_num\"] = (item_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "shop_agg = (\n",
        "    monthly.groupby([\"date_block_num\",\"shop_id\"], as_index=False)\n",
        "           .agg(shop_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                shop_items=(\"item_id\",\"nunique\"))\n",
        ")\n",
        "shop_agg[\"date_block_num\"] = (shop_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "# =========================\n",
        "# 5) Panel denso SOLO para pares del test (maneja sparsity)\n",
        "# =========================\n",
        "test_pairs = test[[\"shop_id\",\"item_id\"]].drop_duplicates()\n",
        "n_pairs = len(test_pairs)\n",
        "\n",
        "months = np.arange(0, test_block + 1, dtype=np.int16)  # 0..34\n",
        "n_months = len(months)\n",
        "\n",
        "panel = pd.DataFrame({\n",
        "    \"date_block_num\": np.tile(months, n_pairs).astype(np.int16),\n",
        "    \"shop_id\": np.repeat(test_pairs[\"shop_id\"].values, n_months).astype(np.int16),\n",
        "    \"item_id\": np.repeat(test_pairs[\"item_id\"].values, n_months).astype(np.int16),\n",
        "})\n",
        "\n",
        "# Merge target/price mensual\n",
        "panel = panel.merge(\n",
        "    monthly[[\"date_block_num\",\"shop_id\",\"item_id\",\"item_cnt_month\",\"price_mean\"]],\n",
        "    on=[\"date_block_num\",\"shop_id\",\"item_id\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# Target: meses sin registro => 0 (esto es CLAVE)\n",
        "panel[\"item_cnt_month\"] = panel[\"item_cnt_month\"].fillna(0).astype(np.float32)\n",
        "\n",
        "# Precio: dejamos NaN cuando no hubo venta (mejor que poner 0)\n",
        "# price_mean se queda NaN si no hubo registro\n",
        "panel[\"price_mean\"] = panel[\"price_mean\"].astype(np.float32)\n",
        "\n",
        "# Calendar\n",
        "panel[\"month\"] = (panel[\"date_block_num\"] % 12).astype(np.int8)\n",
        "panel[\"year\"]  = (panel[\"date_block_num\"] // 12).astype(np.int8)\n",
        "\n",
        "# Encoding cíclico (estacionalidad)\n",
        "panel[\"month_sin\"] = np.sin(2*np.pi*panel[\"month\"]/12).astype(np.float32)\n",
        "panel[\"month_cos\"] = np.cos(2*np.pi*panel[\"month\"]/12).astype(np.float32)\n",
        "\n",
        "# Merge agregados laggeados\n",
        "panel = panel.merge(global_agg, on=\"date_block_num\", how=\"left\")\n",
        "panel = panel.merge(item_agg,   on=[\"date_block_num\",\"item_id\"], how=\"left\")\n",
        "panel = panel.merge(shop_agg,   on=[\"date_block_num\",\"shop_id\"], how=\"left\")\n",
        "\n",
        "# Fill NaNs de agregados (si no existe info previa)\n",
        "for c in [\"global_mean\",\"global_sum\",\"global_pairs\",\"item_mean\",\"item_shops\",\"item_price_mean\",\"shop_mean\",\"shop_items\"]:\n",
        "    panel[c] = panel[c].fillna(0).astype(np.float32)\n",
        "\n",
        "# Limpieza de memoria\n",
        "del train, monthly, global_agg, item_agg, shop_agg, test_pairs\n",
        "gc.collect()\n",
        "\n",
        "# =========================\n",
        "# 6) Precio: clip/log + \"último precio conocido\" (laggeado)\n",
        "# =========================\n",
        "# clip price por percentil (sobre valores observados)\n",
        "p_obs = panel[\"price_mean\"].dropna()\n",
        "p999 = p_obs.quantile(0.999) if len(p_obs) else 0.0\n",
        "\n",
        "price_clip = panel[\"price_mean\"].clip(0, p999)\n",
        "panel[\"log_price_obs\"] = np.where(panel[\"price_mean\"].notna(), np.log1p(price_clip), np.nan).astype(np.float32)\n",
        "\n",
        "# item_price_mean (laggeado) también en log\n",
        "panel[\"item_log_price_mean\"] = np.log1p(panel[\"item_price_mean\"].clip(0, p999)).astype(np.float32)\n",
        "\n",
        "# Orden para operaciones por grupo\n",
        "panel.sort_values([\"shop_id\",\"item_id\",\"date_block_num\"], inplace=True, ignore_index=True)\n",
        "g = panel.groupby([\"shop_id\",\"item_id\"], sort=False)\n",
        "\n",
        "# Último precio observado antes de t\n",
        "panel[\"log_price_last\"] = (\n",
        "    g[\"log_price_obs\"].ffill()            # arrastra último observado\n",
        ")\n",
        "panel[\"log_price_last\"] = (\n",
        "    g[\"log_price_last\"].shift(1)          # lo convierte en \"estrictamente pasado\"\n",
        "    .astype(np.float32)\n",
        ")\n",
        "\n",
        "panel[\"price_missing_last\"] = panel[\"log_price_last\"].isna().astype(np.int8)\n",
        "\n",
        "# Imputación suave: si nunca tuvo precio, usa el promedio del item (laggeado)\n",
        "panel[\"log_price_last\"] = panel[\"log_price_last\"].fillna(panel[\"item_log_price_mean\"]).astype(np.float32)\n",
        "\n",
        "panel[\"price_gap_item\"] = (panel[\"log_price_last\"] - panel[\"item_log_price_mean\"]).astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 7) Lags del target (1..6 y 12)\n",
        "# =========================\n",
        "for lag in [1,2,3,4,5,6,12]:\n",
        "    panel[f\"cnt_lag_{lag}\"] = g[\"item_cnt_month\"].shift(lag).fillna(0).astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 8) Ventanas (desde lags, sin rolling pesado)\n",
        "# =========================\n",
        "eps = 1e-6\n",
        "l1 = panel[\"cnt_lag_1\"]; l2 = panel[\"cnt_lag_2\"]; l3 = panel[\"cnt_lag_3\"]\n",
        "l4 = panel[\"cnt_lag_4\"]; l5 = panel[\"cnt_lag_5\"]; l6 = panel[\"cnt_lag_6\"]\n",
        "l12 = panel[\"cnt_lag_12\"]\n",
        "\n",
        "# last 3\n",
        "panel[\"sum_3\"]  = (l1 + l2 + l3).astype(np.float32)\n",
        "panel[\"mean_3\"] = (panel[\"sum_3\"] / 3.0).astype(np.float32)\n",
        "panel[\"max_3\"]  = np.maximum.reduce([l1.values, l2.values, l3.values]).astype(np.float32)\n",
        "panel[\"nz_3\"]   = ((l1>0).astype(np.int8) + (l2>0).astype(np.int8) + (l3>0).astype(np.int8)).astype(np.int8)\n",
        "\n",
        "mean_sq_3 = ((l1*l1 + l2*l2 + l3*l3) / 3.0).astype(np.float32)\n",
        "panel[\"std_3\"] = np.sqrt(np.maximum(mean_sq_3 - panel[\"mean_3\"]*panel[\"mean_3\"], 0)).astype(np.float32)\n",
        "\n",
        "# last 6\n",
        "panel[\"sum_6\"]  = (l1+l2+l3+l4+l5+l6).astype(np.float32)\n",
        "panel[\"mean_6\"] = (panel[\"sum_6\"]/6.0).astype(np.float32)\n",
        "panel[\"max_6\"]  = np.maximum.reduce([l1.values,l2.values,l3.values,l4.values,l5.values,l6.values]).astype(np.float32)\n",
        "panel[\"nz_6\"]   = ((l1>0)+(l2>0)+(l3>0)+(l4>0)+(l5>0)+(l6>0)).astype(np.int8)\n",
        "\n",
        "mean_sq_6 = ((l1*l1+l2*l2+l3*l3+l4*l4+l5*l5+l6*l6) / 6.0).astype(np.float32)\n",
        "panel[\"std_6\"] = np.sqrt(np.maximum(mean_sq_6 - panel[\"mean_6\"]*panel[\"mean_6\"], 0)).astype(np.float32)\n",
        "\n",
        "# Intermitencia (probabilidad y tamaño)\n",
        "panel[\"rate_6\"] = (panel[\"nz_6\"] / 6.0).astype(np.float32)\n",
        "panel[\"mean_nonzero_6\"] = (panel[\"sum_6\"] / (panel[\"nz_6\"].astype(np.float32) + eps)).astype(np.float32)\n",
        "panel[\"interval_6\"] = (6.0 / (panel[\"nz_6\"].astype(np.float32) + eps)).astype(np.float32)\n",
        "\n",
        "# Régimen\n",
        "panel[\"active_1\"] = (l1 > 0).astype(np.int8)\n",
        "panel[\"dead_6\"]   = (panel[\"nz_6\"] == 0).astype(np.int8)\n",
        "\n",
        "# Tendencias / estacionalidad\n",
        "panel[\"trend_1_3\"]  = (l1 - l3).astype(np.float32)\n",
        "panel[\"trend_1_12\"] = (l1 - l12).astype(np.float32)\n",
        "panel[\"ratio_1_12\"] = (l1 / (l12 + eps)).astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 9) Recency EXACTA (meses desde última venta)\n",
        "# =========================\n",
        "sale_month = panel[\"date_block_num\"].where(panel[\"item_cnt_month\"] > 0, np.nan)\n",
        "\n",
        "# último mes con venta \"hasta ahora\"\n",
        "last_sale_inclusive = sale_month.groupby([panel[\"shop_id\"], panel[\"item_id\"]]).ffill()\n",
        "# último mes con venta estrictamente pasado\n",
        "panel[\"last_sale_month\"] = last_sale_inclusive.groupby([panel[\"shop_id\"], panel[\"item_id\"]]).shift(1)\n",
        "\n",
        "panel[\"recency\"] = (panel[\"date_block_num\"] - panel[\"last_sale_month\"]).fillna(99).clip(0, 99).astype(np.int16)\n",
        "panel.drop(columns=[\"last_sale_month\"], inplace=True)\n",
        "\n",
        "# =========================\n",
        "# 10) Cumulativos (hasta t-1)\n",
        "# =========================\n",
        "panel[\"sold\"] = (panel[\"item_cnt_month\"] > 0).astype(np.int8)\n",
        "panel[\"sold_cum\"] = g[\"sold\"].cumsum().astype(np.int16)\n",
        "panel[\"sold_cum_lag1\"] = g[\"sold_cum\"].shift(1).fillna(0).astype(np.int16)\n",
        "\n",
        "panel[\"sales_cum\"] = g[\"item_cnt_month\"].cumsum().astype(np.float32)\n",
        "panel[\"sales_cum_lag1\"] = g[\"sales_cum\"].shift(1).fillna(0).astype(np.float32)\n",
        "panel[\"log_sales_cum_lag1\"] = np.log1p(panel[\"sales_cum_lag1\"]).astype(np.float32)\n",
        "\n",
        "panel[\"never_sold_before\"] = (panel[\"sold_cum_lag1\"] == 0).astype(np.int8)\n",
        "\n",
        "# =========================\n",
        "# 11) Split train/valid/test\n",
        "# =========================\n",
        "train_df = panel[panel[\"date_block_num\"] <= max_block - 1].copy()  # 0..32\n",
        "valid_df = panel[panel[\"date_block_num\"] == max_block].copy()      # 33\n",
        "test_df  = panel[panel[\"date_block_num\"] == test_block].copy()     # 34\n",
        "\n",
        "y_train = train_df[\"item_cnt_month\"].astype(np.float32)\n",
        "y_valid = valid_df[\"item_cnt_month\"].astype(np.float32)\n",
        "\n",
        "# Features finales (compactas + potentes)\n",
        "feature_cols = [\n",
        "    \"date_block_num\",\"month\",\"year\",\"month_sin\",\"month_cos\",\"shop_id\",\"item_id\",\n",
        "\n",
        "    # macro / popularidad laggeada\n",
        "    \"global_mean\",\"global_sum\",\"global_pairs\",\n",
        "    \"item_mean\",\"item_shops\",\n",
        "    \"shop_mean\",\"shop_items\",\n",
        "\n",
        "    # precio\n",
        "    \"log_price_last\",\"item_log_price_mean\",\"price_gap_item\",\"price_missing_last\",\n",
        "\n",
        "    # lags\n",
        "    \"cnt_lag_1\",\"cnt_lag_2\",\"cnt_lag_3\",\"cnt_lag_4\",\"cnt_lag_5\",\"cnt_lag_6\",\"cnt_lag_12\",\n",
        "\n",
        "    # ventanas/intermitencia/régimen\n",
        "    \"sum_3\",\"mean_3\",\"std_3\",\"max_3\",\"nz_3\",\n",
        "    \"sum_6\",\"mean_6\",\"std_6\",\"max_6\",\"nz_6\",\n",
        "    \"rate_6\",\"mean_nonzero_6\",\"interval_6\",\n",
        "    \"active_1\",\"dead_6\",\n",
        "\n",
        "    # recency/trend\n",
        "    \"recency\",\"trend_1_3\",\"trend_1_12\",\"ratio_1_12\",\n",
        "\n",
        "    # historial\n",
        "    \"sold_cum_lag1\",\"log_sales_cum_lag1\",\"never_sold_before\",\n",
        "]\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "X_valid = valid_df[feature_cols]\n",
        "X_test  = test_df[feature_cols]\n",
        "\n",
        "print(\"Features listos\")\n",
        "print(\"X_train:\", X_train.shape, \"X_valid:\", X_valid.shape, \"X_test:\", X_test.shape)\n",
        "print(\"Ejemplo columnas:\", feature_cols[:10])\n",
        "\n",
        "# (Opcional) libera memoria\n",
        "del panel, train_df, valid_df\n",
        "gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b6rr9nhSHkn",
        "outputId": "2b192fec-040a-46b4-e0b7-1532bf51eae7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "OUT_DIR = \"intermediate_data\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# 1) Guarda datasets\n",
        "train_out = X_train.copy()\n",
        "train_out[\"y\"] = y_train.values\n",
        "\n",
        "valid_out = X_valid.copy()\n",
        "valid_out[\"y\"] = y_valid.values\n",
        "\n",
        "test_out = X_test.copy()\n",
        "\n",
        "# (Opcional pero útil) Guardar shop/item para unir con test.csv después\n",
        "test_meta = test_df[[\"shop_id\",\"item_id\"]].copy()  # test_df es el del mes test_block\n",
        "test_meta[\"ID\"] = None  # lo llenaremos al merge con test.csv en Notebook 3\n",
        "\n",
        "# Parquet comprimido\n",
        "train_out.to_parquet(f\"{OUT_DIR}/train.parquet\", index=False)\n",
        "valid_out.to_parquet(f\"{OUT_DIR}/valid.parquet\", index=False)\n",
        "test_out.to_parquet(f\"{OUT_DIR}/test_features.parquet\", index=False)\n",
        "\n",
        "# También guarda el mapping shop-item del test mes\n",
        "test_meta.to_parquet(f\"{OUT_DIR}/test_pairs.parquet\", index=False)\n",
        "\n",
        "# 2) Guarda metadata (columnas + params)\n",
        "meta = {\n",
        "    \"feature_cols\": feature_cols,\n",
        "    \"max_block\": int(max_block),\n",
        "    \"test_block\": int(test_block),\n",
        "}\n",
        "with open(f\"{OUT_DIR}/meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(\"guardado en:\", OUT_DIR)\n",
        "print(os.listdir(OUT_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYm6Th23Suhu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Si cargaste parquet intermedio:\n",
        "# train_out = pd.read_parquet(\"intermediate_data/train.parquet\")\n",
        "\n",
        "df = train_out.copy()  # <- o tu train_df con y\n",
        "y_col = \"y\"\n",
        "\n",
        "df[y_col] = df[y_col].astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "PbULFmCWVJst",
        "outputId": "c8db7a89-37c5-4461-abba-42dd04b7e3f2"
      },
      "outputs": [],
      "source": [
        "na = (df.isna().mean().sort_values(ascending=False) * 100).head(25)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(na.index.astype(str), na.values)\n",
        "plt.title(\"Top 25 features con % de NaN (después de feature engineering)\")\n",
        "plt.ylabel(\"% NaN\")\n",
        "plt.xticks(rotation=75, ha=\"right\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "o1bWq513VNvL",
        "outputId": "190ea32b-e716-477c-83f2-2d08bda41bf9"
      },
      "outputs": [],
      "source": [
        "df[\"sold_now\"] = (df[y_col] > 0).astype(int)\n",
        "\n",
        "# Bins de recency\n",
        "bins = [-1,0,1,2,3,4,6,9,12,18,24,50,100]\n",
        "df[\"rec_bin\"] = pd.cut(df[\"recency\"], bins=bins)\n",
        "\n",
        "grp = df.groupby(\"rec_bin\")[\"sold_now\"].mean()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(grp.index.astype(str), grp.values, marker=\"o\")\n",
        "plt.title(\"Probabilidad de venta (y>0) vs recency (binned)\")\n",
        "plt.ylabel(\"P(y>0)\")\n",
        "plt.xticks(rotation=60, ha=\"right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "GqAmB4cXVRAz",
        "outputId": "ac465f8a-9ee1-461c-b9f2-cc7e21f176c9"
      },
      "outputs": [],
      "source": [
        "# rate_6 ya está en 0..1\n",
        "bins = np.linspace(0, 1, 11)\n",
        "df[\"rate_bin\"] = pd.cut(df[\"rate_6\"], bins=bins, include_lowest=True)\n",
        "\n",
        "p_sold = df.groupby(\"rate_bin\")[\"sold_now\"].mean()\n",
        "mean_y = df.groupby(\"rate_bin\")[y_col].mean()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(p_sold.index.astype(str), p_sold.values, marker=\"o\", label=\"P(y>0)\")\n",
        "plt.plot(mean_y.index.astype(str), mean_y.values, marker=\"o\", label=\"E[y]\")\n",
        "plt.title(\"Intermitencia reciente: rate_6 vs probabilidad y nivel de ventas\")\n",
        "plt.xticks(rotation=60, ha=\"right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "QJuulTKqVYFJ",
        "outputId": "a5c1c69c-de7e-4021-dd0c-f2bb6cc25925"
      },
      "outputs": [],
      "source": [
        "# recency bins y rate bins\n",
        "df[\"rec_b\"] = pd.cut(df[\"recency\"], bins=[-1,0,1,2,3,6,12,24,99])\n",
        "df[\"rate_b\"] = pd.cut(df[\"rate_6\"], bins=np.linspace(0,1,6), include_lowest=True)\n",
        "\n",
        "pivot = df.pivot_table(values=y_col, index=\"rec_b\", columns=\"rate_b\", aggfunc=\"mean\").fillna(0)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.imshow(pivot.values, aspect=\"auto\")\n",
        "plt.title(\"E[y] por (recency × rate_6)\")\n",
        "plt.xlabel(\"rate_6 (binned)\")\n",
        "plt.ylabel(\"recency (binned)\")\n",
        "plt.xticks(range(len(pivot.columns)), [str(c) for c in pivot.columns], rotation=45, ha=\"right\")\n",
        "plt.yticks(range(len(pivot.index)), [str(i) for i in pivot.index])\n",
        "plt.colorbar(label=\"E[y]\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "nkM_v3wnVcge",
        "outputId": "64a21244-03d8-4289-a349-ca8dbd41c8e3"
      },
      "outputs": [],
      "source": [
        "m = df.groupby(\"month\")[y_col].mean()\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(m.index, m.values, marker=\"o\")\n",
        "plt.title(\"E[y] por mes (estacionalidad promedio)\")\n",
        "plt.xlabel(\"month (0=Ene)\")\n",
        "plt.ylabel(\"E[y]\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "RLQa_f05VgGk",
        "outputId": "09359c31-6a8b-4c2d-cc4d-ac5dadd11f2b"
      },
      "outputs": [],
      "source": [
        "grp = df.groupby(\"never_sold_before\")[y_col].agg([\"mean\",\"count\"])\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.bar([\"sold_before=0\",\"sold_before=1\"], grp[\"mean\"].values)\n",
        "plt.title(\"E[y] si nunca vendió antes vs ya vendió\")\n",
        "plt.ylabel(\"E[y]\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(grp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "-7NOkFdHVj2y",
        "outputId": "8bc9dae4-5bdb-4dff-d158-26e3670bc9d5"
      },
      "outputs": [],
      "source": [
        "# recorta extremos para visualizar\n",
        "x = df[\"price_gap_item\"].clip(df[\"price_gap_item\"].quantile(0.01), df[\"price_gap_item\"].quantile(0.99))\n",
        "bins = pd.qcut(x, 10, duplicates=\"drop\")\n",
        "\n",
        "g = df.groupby(bins)[y_col].mean()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(g.index.astype(str), g.values, marker=\"o\")\n",
        "plt.title(\"E[y] vs price_gap_item (deciles, clip p1–p99)\")\n",
        "plt.xticks(rotation=60, ha=\"right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O80SfdXlVo9S",
        "outputId": "c6f46b18-5c33-445c-f672-8b2f06de5f41"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Si tu target se llama y:\n",
        "y_col = \"y\"  # cambia a \"item_cnt_month\" si aplica\n",
        "\n",
        "df = train_out.copy()  # o el dataframe que estés usando para train\n",
        "df = df.sort_values([\"shop_id\",\"item_id\",\"date_block_num\"]).copy()\n",
        "\n",
        "g = df.groupby([\"shop_id\",\"item_id\"], sort=False)\n",
        "\n",
        "# vendió este mes\n",
        "df[\"sold_now\"] = (df[y_col] > 0).astype(np.int8)\n",
        "\n",
        "# acumulado HASTA EL MES ANTERIOR (shift(1) evita leakage)\n",
        "df[\"sold_cum_lag1\"] = g[\"sold_now\"].cumsum().shift(1).fillna(0).astype(np.int16)\n",
        "\n",
        "# nunca vendió antes (hasta t-1)\n",
        "df[\"never_sold_before\"] = (df[\"sold_cum_lag1\"] == 0).astype(np.int8)\n",
        "\n",
        "# sanity check rápido\n",
        "print(df.groupby(\"never_sold_before\")[y_col].agg([\"mean\",\"count\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "3edi_p2mW7Tx",
        "outputId": "84cc00df-360b-4c31-cc2a-b0e579fbca4e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "grp = df.groupby(\"never_sold_before\")[y_col].mean()\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar([\"has_sold_before (0)\", \"never_sold_before (1)\"], [grp.get(0,0), grp.get(1,0)])\n",
        "plt.title(\"E[y] según historial de ventas (sin leakage)\")\n",
        "plt.ylabel(\"E[y]\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP5TqfYzvQn6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxZF5pMCvQ-9"
      },
      "source": [
        "### MODELACIÓN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFq40Sq1vEKU",
        "outputId": "4314c0ad-9446-41f0-c5be-be327c0a39e5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "OUT_DIR = \"intermediate_data\"\n",
        "\n",
        "train_df = pd.read_parquet(f\"{OUT_DIR}/train.parquet\")\n",
        "valid_df = pd.read_parquet(f\"{OUT_DIR}/valid.parquet\")\n",
        "test_X   = pd.read_parquet(f\"{OUT_DIR}/test_features.parquet\")\n",
        "\n",
        "with open(f\"{OUT_DIR}/meta.json\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "feature_cols = meta[\"feature_cols\"]\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[\"y\"].astype(\"float32\")\n",
        "\n",
        "X_valid = valid_df[feature_cols]\n",
        "y_valid = valid_df[\"y\"].astype(\"float32\")\n",
        "\n",
        "X_test  = test_X[feature_cols]\n",
        "\n",
        "# Categóricas (IDs/mes/año)\n",
        "cat_features = [c for c in [\"shop_id\",\"item_id\",\"month\",\"year\"] if c in feature_cols]\n",
        "\n",
        "# =========================\n",
        "# 1) Etapa 1: Clasificación (y>0)\n",
        "# =========================\n",
        "y_train_bin = (y_train > 0).astype(int)\n",
        "y_valid_bin = (y_valid > 0).astype(int)\n",
        "\n",
        "clf = lgb.LGBMClassifier(\n",
        "    n_estimators=6000,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=256,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train, y_train_bin,\n",
        "    eval_set=[(X_valid, y_valid_bin)],\n",
        "    eval_metric=\"binary_logloss\",\n",
        "    categorical_feature=cat_features,\n",
        "    callbacks=[lgb.early_stopping(200, verbose=True)]\n",
        ")\n",
        "\n",
        "p_valid = clf.predict_proba(X_valid)[:, 1].astype(np.float32)\n",
        "p_test  = clf.predict_proba(X_test)[:, 1].astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 2) Etapa 2: Regresión SOLO donde y>0\n",
        "# =========================\n",
        "mask_pos_tr = y_train > 0\n",
        "mask_pos_va = y_valid > 0\n",
        "\n",
        "reg = lgb.LGBMRegressor(\n",
        "    n_estimators=8000,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=256,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42,\n",
        "    objective=\"regression\"  # (alternativa a probar: \"poisson\")\n",
        ")\n",
        "\n",
        "reg.fit(\n",
        "    X_train.loc[mask_pos_tr], y_train.loc[mask_pos_tr],\n",
        "    eval_set=[(X_valid.loc[mask_pos_va], y_valid.loc[mask_pos_va])],\n",
        "    eval_metric=\"rmse\",\n",
        "    categorical_feature=cat_features,\n",
        "    callbacks=[lgb.early_stopping(200, verbose=True)]\n",
        ")\n",
        "\n",
        "mu_valid = reg.predict(X_valid).astype(np.float32)\n",
        "mu_test  = reg.predict(X_test).astype(np.float32)\n",
        "\n",
        "# =========================\n",
        "# 3) Combinar (hurdle)\n",
        "# =========================\n",
        "pred_valid = (p_valid * mu_valid).clip(0, 20)\n",
        "pred_test  = (p_test  * mu_test ).clip(0, 20)\n",
        "\n",
        "rmse = np.sqrt(np.mean((pred_valid - y_valid.values)**2))\n",
        "print(\"RMSE valid (hurdle):\", rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K790auOpvTgi",
        "outputId": "ae146406-4dcc-4995-9e4a-d495cfe53b13"
      },
      "outputs": [],
      "source": [
        "pred_map = pd.DataFrame({\n",
        "    \"shop_id\": test_df[\"shop_id\"].values,   # <- tu dataframe de features para test (mes 34)\n",
        "    \"item_id\": test_df[\"item_id\"].values,\n",
        "    \"item_cnt_month\": pred_test.astype(np.float32)\n",
        "})\n",
        "\n",
        "# 3) Merge y clip\n",
        "sub = test.merge(pred_map, on=[\"shop_id\",\"item_id\"], how=\"left\")\n",
        "sub[\"item_cnt_month\"] = sub[\"item_cnt_month\"].fillna(0).clip(0, 20)\n",
        "\n",
        "# 4) Guardar submission\n",
        "submission = sub[[\"ID\",\"item_cnt_month\"]]\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Guardado: submission.csv\")\n",
        "print(submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "ICDjnTr1w2O-",
        "outputId": "38b72f66-4189-4904-bf9c-f9e47353d517"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def decile_report(y_true, y_pred, n_bins=10, clip=(0,20)):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "\n",
        "    if clip is not None:\n",
        "        y_pred = np.clip(y_pred, clip[0], clip[1])\n",
        "\n",
        "    df = pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred})\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    # deciles por predicción (si hay muchos empates, qcut puede bajar bins; por eso duplicates=\"drop\")\n",
        "    df[\"decile\"] = pd.qcut(df[\"y_pred\"], q=n_bins, duplicates=\"drop\")\n",
        "\n",
        "    rep = df.groupby(\"decile\").apply(\n",
        "        lambda g: pd.Series({\n",
        "            \"n\": len(g),\n",
        "            \"pred_mean\": g[\"y_pred\"].mean(),\n",
        "            \"true_mean\": g[\"y_true\"].mean(),\n",
        "            \"pred_median\": g[\"y_pred\"].median(),\n",
        "            \"true_median\": g[\"y_true\"].median(),\n",
        "            \"mae\": np.mean(np.abs(g[\"y_true\"] - g[\"y_pred\"])),\n",
        "            \"rmse\": np.sqrt(np.mean((g[\"y_true\"] - g[\"y_pred\"])**2)),\n",
        "            \"p_sold_true\": np.mean(g[\"y_true\"] > 0),\n",
        "        })\n",
        "    ).reset_index()\n",
        "\n",
        "    return rep, df\n",
        "\n",
        "rep, df_dec = decile_report(y_valid, pred_valid, n_bins=10, clip=(0,20))\n",
        "print(rep[[\"decile\",\"n\",\"pred_mean\",\"true_mean\",\"mae\",\"rmse\",\"p_sold_true\"]])\n",
        "\n",
        "# Plot: promedio por decil\n",
        "x = np.arange(len(rep))\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(x, rep[\"pred_mean\"], marker=\"o\", linewidth=1, label=\"Predicho (mean)\")\n",
        "plt.plot(x, rep[\"true_mean\"], marker=\"o\", linewidth=1, label=\"Real (mean)\")\n",
        "plt.title(\"Calibración por deciles (ordenados por ŷ): promedio real vs predicho\")\n",
        "plt.xlabel(\"Decil (0=ŷ más bajo, último=ŷ más alto)\")\n",
        "plt.ylabel(\"Promedio\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4BAIu8Y2aCS",
        "outputId": "97264c5e-1b4c-4956-b444-46d607b7749a"
      },
      "outputs": [],
      "source": [
        "dfv = pd.DataFrame({\"y\": y_valid, \"yhat\": pred_valid}).copy()\n",
        "\n",
        "for thr in [5, 10, 15]:\n",
        "    sub = dfv[dfv[\"y\"] >= thr]\n",
        "    rmse = np.sqrt(np.mean((sub[\"y\"] - sub[\"yhat\"])**2))\n",
        "    mae  = np.mean(np.abs(sub[\"y\"] - sub[\"yhat\"]))\n",
        "    print(f\"y>={thr}: n={len(sub)}  mean(y)={sub['y'].mean():.2f}  mean(yhat)={sub['yhat'].mean():.2f}  MAE={mae:.2f}  RMSE={rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9xjYq2e3la4",
        "outputId": "fc4aa81e-474c-488e-851c-c9fed0fe85da"
      },
      "outputs": [],
      "source": [
        "dfv[\"y_dec\"] = pd.qcut(dfv[\"y\"], 10, duplicates=\"drop\")\n",
        "rep = dfv.groupby(\"y_dec\").agg(\n",
        "    n=(\"y\",\"size\"),\n",
        "    y_mean=(\"y\",\"mean\"),\n",
        "    yhat_mean=(\"yhat\",\"mean\"),\n",
        "    rmse=(\"y\", lambda s: np.sqrt(np.mean((s - dfv.loc[s.index, \"yhat\"])**2)))\n",
        ").reset_index()\n",
        "\n",
        "print(rep[[\"y_dec\",\"n\",\"y_mean\",\"yhat_mean\",\"rmse\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "PomHpCtH3yjt",
        "outputId": "7820a71f-9382-41c4-89f1-3c28644d1a1c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dfv = pd.DataFrame({\"y\": y_valid, \"yhat\": pred_valid}).copy()\n",
        "dfv = dfv.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "# 1) Barras: promedio real vs predicho para umbrales\n",
        "thresholds = [0, 5, 10, 15]\n",
        "rows = []\n",
        "for thr in thresholds:\n",
        "    sub = dfv[dfv[\"y\"] >= thr]\n",
        "    rows.append({\n",
        "        \"thr\": thr,\n",
        "        \"n\": len(sub),\n",
        "        \"mean_y\": sub[\"y\"].mean(),\n",
        "        \"mean_yhat\": sub[\"yhat\"].mean(),\n",
        "        \"rmse\": np.sqrt(np.mean((sub[\"y\"] - sub[\"yhat\"])**2)),\n",
        "        \"mae\": np.mean(np.abs(sub[\"y\"] - sub[\"yhat\"])),\n",
        "    })\n",
        "rep_thr = pd.DataFrame(rows)\n",
        "\n",
        "x = np.arange(len(rep_thr))\n",
        "w = 0.35\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(x - w/2, rep_thr[\"mean_y\"], width=w, label=\"Real (mean)\")\n",
        "plt.bar(x + w/2, rep_thr[\"mean_yhat\"], width=w, label=\"Predicho (mean)\")\n",
        "plt.title(\"Subestimación en la cola: promedio real vs predicho por umbral de y\")\n",
        "plt.xticks(x, [f\"y≥{t}\\n(n={n})\" for t,n in zip(rep_thr[\"thr\"], rep_thr[\"n\"])])\n",
        "plt.ylabel(\"Promedio\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Scatter (zoom): y vs yhat para y>=5\n",
        "sub = dfv[dfv[\"y\"] >= 5].copy()\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(sub[\"y\"], sub[\"yhat\"], s=6, alpha=0.2)\n",
        "mx = max(sub[\"y\"].max(), sub[\"yhat\"].max(), 20)\n",
        "plt.plot([0,mx],[0,mx], linewidth=1)  # línea perfecta\n",
        "plt.title(\"y real vs y predicho (solo casos con y≥5)\")\n",
        "plt.xlabel(\"y real\")\n",
        "plt.ylabel(\"y predicho\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iZ6aois4jBB",
        "outputId": "61d60b4d-c71a-480c-de70-26439704a91e"
      },
      "outputs": [],
      "source": [
        "print('print hola mundo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "qc0DTIn5H8A6",
        "outputId": "99c7b9be-7c98-4f63-fda7-38060a1cca33"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "res = y_valid - pred_valid\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(res, bins=80)\n",
        "plt.title(\"Residuales en validación (y − ŷ)\")\n",
        "plt.xlabel(\"y − ŷ\")\n",
        "plt.ylabel(\"freq\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Bias (mean residual):\", float(np.mean(res)))\n",
        "print(\"MAE:\", float(np.mean(np.abs(res))))\n",
        "print(\"RMSE:\", float(np.sqrt(np.mean(res**2))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "FmMoSilIKhLj",
        "outputId": "570d9422-5bbf-44e8-d96e-009144018137"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(pred_valid, (y_valid - pred_valid), s=6, alpha=0.2)\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.title(\"Residual vs ŷ (validación mes 33)\")\n",
        "plt.xlabel(\"ŷ\")\n",
        "plt.ylabel(\"y − ŷ\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "id": "IVc4qFrSKsqc",
        "outputId": "871e3f1c-e67c-47eb-9fa5-d584540248a0"
      },
      "outputs": [],
      "source": [
        "\n",
        "dfv = pd.DataFrame({\n",
        "    \"recency\": X_valid[\"recency\"],\n",
        "    \"y\": y_valid,\n",
        "    \"yhat\": pred_valid\n",
        "})\n",
        "\n",
        "dfv[\"rec_bin\"] = pd.cut(dfv[\"recency\"], bins=[-1,0,1,2,3,6,12,24,99])\n",
        "rep = dfv.groupby(\"rec_bin\").apply(lambda g: pd.Series({\n",
        "    \"n\": len(g),\n",
        "    \"rmse\": np.sqrt(np.mean((g[\"y\"]-g[\"yhat\"])**2)),\n",
        "    \"mean_y\": g[\"y\"].mean(),\n",
        "    \"mean_yhat\": g[\"yhat\"].mean(),\n",
        "    \"p_sold\": np.mean(g[\"y\"]>0)\n",
        "})).reset_index()\n",
        "\n",
        "x = np.arange(len(rep))\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(x, rep[\"rmse\"], marker=\"o\")\n",
        "plt.title(\"RMSE por recency (validación)\")\n",
        "plt.xlabel(\"Recency bin (ordenado)\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(x, rep[\"mean_y\"], marker=\"o\", label=\"Real mean\")\n",
        "plt.plot(x, rep[\"mean_yhat\"], marker=\"o\", label=\"Pred mean\")\n",
        "plt.title(\"Promedio real vs predicho por recency\")\n",
        "plt.xlabel(\"Recency bin (ordenado)\")\n",
        "plt.ylabel(\"Promedio\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnkKjToK0hH",
        "outputId": "161f2823-af48-4c29-80cb-1dd5c4983582"
      },
      "outputs": [],
      "source": [
        "print(\"unique months:\", sorted(pd.Series(X_valid[\"month\"]).unique()))\n",
        "print(\"n unique:\", pd.Series(X_valid[\"month\"]).nunique())\n",
        "print(\"date_block_num unique:\", pd.Series(X_valid[\"date_block_num\"]).unique()[:10], \" ... nunique=\", pd.Series(X_valid[\"date_block_num\"]).nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "xeyYrnuzMkTJ",
        "outputId": "90359d52-bd19-4838-c71a-fc6c55fe3910"
      },
      "outputs": [],
      "source": [
        "dfv = pd.DataFrame({\n",
        "    \"rate_6\": X_valid[\"rate_6\"],\n",
        "    \"y\": y_valid,\n",
        "    \"yhat\": pred_valid\n",
        "})\n",
        "dfv[\"rate_bin\"] = pd.cut(dfv[\"rate_6\"], bins=[-0.001, 0.001, 0.2, 0.5, 1.0])\n",
        "\n",
        "rep = dfv.groupby(\"rate_bin\").apply(lambda g: pd.Series({\n",
        "    \"n\": len(g),\n",
        "    \"rmse\": np.sqrt(np.mean((g[\"y\"]-g[\"yhat\"])**2)),\n",
        "    \"mean_y\": g[\"y\"].mean(),\n",
        "    \"mean_yhat\": g[\"yhat\"].mean(),\n",
        "    \"p_sold\": np.mean(g[\"y\"]>0)\n",
        "})).reset_index()\n",
        "\n",
        "x = np.arange(len(rep))\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(x, rep[\"rmse\"], marker=\"o\")\n",
        "plt.title(\"RMSE por intermitencia (rate_6)\")\n",
        "plt.xlabel(\"rate_6 bin\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "6Pe_yhycNbBR",
        "outputId": "e75b0f7d-d2fb-4c91-d98b-44735bdfa190"
      },
      "outputs": [],
      "source": [
        "dfv = pd.DataFrame({\n",
        "    \"recency\": X_valid[\"recency\"],\n",
        "    \"rate_6\": X_valid[\"rate_6\"],\n",
        "    \"y\": y_valid,\n",
        "    \"yhat\": pred_valid\n",
        "})\n",
        "dfv[\"rec_b\"] = pd.cut(dfv[\"recency\"], bins=[-1,0,1,2,3,6,12,24,99])\n",
        "dfv[\"rate_b\"] = pd.cut(dfv[\"rate_6\"], bins=[-0.001, 0.001, 0.2, 0.5, 1.0])\n",
        "\n",
        "pivot_bias = dfv.pivot_table(values=\"y\", index=\"rec_b\", columns=\"rate_b\",\n",
        "                             aggfunc=lambda s: np.mean(s - dfv.loc[s.index,\"yhat\"])).fillna(0)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.imshow(pivot_bias.values, aspect=\"auto\")\n",
        "plt.title(\"Sesgo (mean(y−ŷ)) por recency × rate_6\")\n",
        "plt.xlabel(\"rate_6 bin\")\n",
        "plt.ylabel(\"recency bin\")\n",
        "plt.xticks(range(len(pivot_bias.columns)), [str(c) for c in pivot_bias.columns], rotation=45, ha=\"right\")\n",
        "plt.yticks(range(len(pivot_bias.index)), [str(i) for i in pivot_bias.index])\n",
        "plt.colorbar(label=\"bias\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "AlzF-ja7Nd10",
        "outputId": "cec30fde-f9ef-4426-c484-f8059a86f9cc"
      },
      "outputs": [],
      "source": [
        "dfv = X_valid.copy()\n",
        "dfv[\"y\"] = y_valid\n",
        "dfv[\"yhat\"] = pred_valid\n",
        "dfv[\"abs_err\"] = np.abs(dfv[\"y\"] - dfv[\"yhat\"])\n",
        "\n",
        "cols_show = [\"shop_id\",\"item_id\",\"recency\",\"rate_6\",\"cnt_lag_1\",\"cnt_lag_12\",\"y\",\"yhat\",\"abs_err\"]\n",
        "display(dfv.sort_values(\"abs_err\", ascending=False)[cols_show].head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYCSVwuKNj4F",
        "outputId": "998fa69b-1909-4ed7-83ba-86854c50ea95"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "bundle = {\n",
        "    \"clf\": clf,\n",
        "    \"reg\": reg,\n",
        "    \"feature_cols\": feature_cols,\n",
        "    \"cat_features\": cat_features,\n",
        "    \"meta\": meta  # opcional, pero útil\n",
        "}\n",
        "\n",
        "joblib.dump(bundle, \"model_tarea1.pkl\")\n",
        "print(\"Guardado: model_tarea1.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMo-PatleZFt",
        "outputId": "1803983c-520f-4da5-9ef3-e18d6fd5da9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from math import sqrt\n",
        "\n",
        "OUT_DIR = \"intermediate_data\"\n",
        "\n",
        "# Carga base de validación (mes 33)\n",
        "valid = pd.read_parquet(f\"{OUT_DIR}/valid.parquet\")\n",
        "\n",
        "# Carga modelo hurdle\n",
        "bundle = joblib.load(\"model_tarea1.pkl\")\n",
        "clf = bundle[\"clf\"]\n",
        "reg = bundle[\"reg\"]\n",
        "feature_cols = bundle[\"feature_cols\"]\n",
        "\n",
        "X_valid = valid[feature_cols]\n",
        "y_true = valid[\"y\"].astype(np.float32).values\n",
        "\n",
        "# Predicción del modelo (hurdle)\n",
        "p = clf.predict_proba(X_valid)[:, 1].astype(np.float32)\n",
        "mu = reg.predict(X_valid).astype(np.float32)\n",
        "yhat_model = np.clip(p * mu, 0, 20)\n",
        "\n",
        "# Baseline: forecast = lag1 (si existe)\n",
        "if \"cnt_lag_1\" in valid.columns:\n",
        "    yhat_lag1 = np.clip(valid[\"cnt_lag_1\"].astype(np.float32).values, 0, 20)\n",
        "else:\n",
        "    raise ValueError(\"No encuentro cnt_lag_1 en valid.parquet para baseline.\")\n",
        "\n",
        "# Parámetros de inventario (ajustables)\n",
        "service_level = 0.95\n",
        "z_map = {0.90: 1.2816, 0.95: 1.6449, 0.97: 1.8808, 0.99: 2.3263}\n",
        "z = z_map.get(service_level, 1.6449)\n",
        "\n",
        "holding_cost_per_unit = 1.0      # costo de mantener 1 unidad al fin de mes\n",
        "stockout_cost_per_unit = 4.0     # penalización por unidad no satisfecha (proxy de margen/NPS)\n",
        "\n",
        "# Inventario inicial al inicio del mes: aproximación (lo típico: venías con stock ~ demanda del mes anterior)\n",
        "# Usamos lag1 como \"stock planeado\" (puedes cambiarlo por otra regla)\n",
        "on_hand0 = yhat_lag1.copy()\n",
        "\n",
        "def simulate_policy(y_true, y_forecast, on_hand0, z, sigma,\n",
        "                    h=1.0, p=4.0):\n",
        "    \"\"\"\n",
        "    Política order-up-to:\n",
        "    target = forecast + z*sigma\n",
        "    order = max(0, target - on_hand)\n",
        "    sales = min(on_hand + order, demand)\n",
        "    end_inventory = on_hand + order - sales\n",
        "    lost_sales = demand - sales\n",
        "    \"\"\"\n",
        "    target = np.clip(y_forecast + z * sigma, 0, 20)  # coherente con clipping del problema\n",
        "    order_qty = np.maximum(0.0, target - on_hand0)\n",
        "\n",
        "    available = on_hand0 + order_qty\n",
        "    sales = np.minimum(available, y_true)\n",
        "\n",
        "    end_inv = available - sales\n",
        "    lost = y_true - sales\n",
        "\n",
        "    holding_cost = h * end_inv\n",
        "    stockout_cost = p * lost\n",
        "\n",
        "    return {\n",
        "        \"target\": target,\n",
        "        \"order_qty\": order_qty,\n",
        "        \"sales\": sales,\n",
        "        \"end_inv\": end_inv,\n",
        "        \"lost\": lost,\n",
        "        \"holding_cost\": holding_cost,\n",
        "        \"stockout_cost\": stockout_cost,\n",
        "        \"total_cost\": holding_cost + stockout_cost,\n",
        "        \"fill_rate\": sales.sum() / (y_true.sum() + 1e-9),\n",
        "        \"service_level\": np.mean(lost == 0),  # % de pares sin quiebre\n",
        "    }\n",
        "\n",
        "# Estima sigma del error (en unidades)\n",
        "sigma_model = float(np.std(y_true - yhat_model))\n",
        "sigma_lag1  = float(np.std(y_true - yhat_lag1))\n",
        "\n",
        "sim_model = simulate_policy(y_true, yhat_model, on_hand0, z, sigma_model,\n",
        "                            h=holding_cost_per_unit, p=stockout_cost_per_unit)\n",
        "\n",
        "sim_lag1  = simulate_policy(y_true, yhat_lag1, on_hand0, z, sigma_lag1,\n",
        "                            h=holding_cost_per_unit, p=stockout_cost_per_unit)\n",
        "\n",
        "summary = pd.DataFrame([\n",
        "    {\n",
        "        \"policy\": \"model_hurdle\",\n",
        "        \"fill_rate\": sim_model[\"fill_rate\"],\n",
        "        \"service_level\": sim_model[\"service_level\"],\n",
        "        \"lost_units\": sim_model[\"lost\"].sum(),\n",
        "        \"ending_inventory\": sim_model[\"end_inv\"].sum(),\n",
        "        \"total_cost\": sim_model[\"total_cost\"].sum(),\n",
        "        \"holding_cost\": sim_model[\"holding_cost\"].sum(),\n",
        "        \"stockout_cost\": sim_model[\"stockout_cost\"].sum(),\n",
        "        \"sigma_used\": sigma_model,\n",
        "    },\n",
        "    {\n",
        "        \"policy\": \"baseline_lag1\",\n",
        "        \"fill_rate\": sim_lag1[\"fill_rate\"],\n",
        "        \"service_level\": sim_lag1[\"service_level\"],\n",
        "        \"lost_units\": sim_lag1[\"lost\"].sum(),\n",
        "        \"ending_inventory\": sim_lag1[\"end_inv\"].sum(),\n",
        "        \"total_cost\": sim_lag1[\"total_cost\"].sum(),\n",
        "        \"holding_cost\": sim_lag1[\"holding_cost\"].sum(),\n",
        "        \"stockout_cost\": sim_lag1[\"stockout_cost\"].sum(),\n",
        "        \"sigma_used\": sigma_lag1,\n",
        "    }\n",
        "])\n",
        "\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lHAllerqykBe",
        "outputId": "f4722d89-1e5a-48d8-a2cc-330bc3ac9d62"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1) Comparación de costos\n",
        "labels = [\"holding_cost\", \"stockout_cost\", \"total_cost\"]\n",
        "x = np.arange(len(labels))\n",
        "w = 0.35\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.bar(x - w/2, [sim_model[k].sum() for k in labels], width=w, label=\"model_hurdle\")\n",
        "plt.bar(x + w/2, [sim_lag1[k].sum() for k in labels], width=w, label=\"baseline_lag1\")\n",
        "plt.xticks(x, labels)\n",
        "plt.title(\"Costo operacional simulado: sobrestock vs stockouts\")\n",
        "plt.ylabel(\"costo total\")\n",
        "plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2) Distribución de inventario final (sobrestock proxy)\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(sim_model[\"end_inv\"], bins=50, alpha=0.6, label=\"model_hurdle\")\n",
        "plt.hist(sim_lag1[\"end_inv\"], bins=50, alpha=0.6, label=\"baseline_lag1\")\n",
        "plt.title(\"Distribución de inventario final (end_inv)\")\n",
        "plt.xlabel(\"unidades\")\n",
        "plt.ylabel(\"frecuencia\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3) Distribución de faltantes (stockouts)\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.hist(sim_model[\"lost\"], bins=50, alpha=0.6, label=\"model_hurdle\")\n",
        "plt.hist(sim_lag1[\"lost\"], bins=50, alpha=0.6, label=\"baseline_lag1\")\n",
        "plt.title(\"Distribución de faltantes (lost sales units)\")\n",
        "plt.xlabel(\"unidades no atendidas\")\n",
        "plt.ylabel(\"frecuencia\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZJi8Hiny022",
        "outputId": "94236423-b86f-4b87-ddc9-85034e04015d"
      },
      "outputs": [],
      "source": [
        "print(\"model lost_units:\", sim_model[\"lost\"].sum(), \"fill_rate:\", sim_model[\"fill_rate\"], \"service:\", sim_model[\"service_level\"])\n",
        "print(\"lag1  lost_units:\", sim_lag1[\"lost\"].sum(),  \"fill_rate:\", sim_lag1[\"fill_rate\"],  \"service:\", sim_lag1[\"service_level\"])\n",
        "print(\"model stockout_cost:\", sim_model[\"stockout_cost\"].sum(), \"lag1 stockout_cost:\", sim_lag1[\"stockout_cost\"].sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htqOsCZLZboH",
        "outputId": "effcd153-4106-4c82-eebf-3777385e5caf"
      },
      "outputs": [],
      "source": [
        "mask_hi = y_true >= 5\n",
        "print(\"lost_units (y>=5) model:\", sim_model[\"lost\"][mask_hi].sum(), \"lag1:\", sim_lag1[\"lost\"][mask_hi].sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVp3f_p3Zm5F",
        "outputId": "477bad10-d408-4a56-a660-2a89dc1998ae"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def simulate_policy(y_true, y_forecast, on_hand0, z, sigma, h=1.0, p=4.0):\n",
        "    target = np.clip(y_forecast + z * sigma, 0, 20)\n",
        "    order_qty = np.maximum(0.0, target - on_hand0)\n",
        "\n",
        "    available = on_hand0 + order_qty\n",
        "    sales = np.minimum(available, y_true)\n",
        "\n",
        "    end_inv = available - sales\n",
        "    lost = y_true - sales\n",
        "\n",
        "    holding_cost = h * end_inv\n",
        "    stockout_cost = p * lost\n",
        "\n",
        "    return {\n",
        "        \"end_inv\": end_inv,\n",
        "        \"lost\": lost,\n",
        "        \"holding_cost\": holding_cost.sum(),\n",
        "        \"stockout_cost\": stockout_cost.sum(),\n",
        "        \"total_cost\": (holding_cost + stockout_cost).sum(),\n",
        "        \"fill_rate\": sales.sum() / (y_true.sum() + 1e-9),\n",
        "        \"service_level\": np.mean(lost == 0),\n",
        "        \"lost_units\": lost.sum(),\n",
        "    }\n",
        "\n",
        "# Rango de penalizaciones por stockout (ajusta a gusto)\n",
        "stockout_cost_grid = [0, 1, 2, 4, 6, 8, 10, 15, 20, 30, 40, 50]\n",
        "\n",
        "rows = []\n",
        "for p_cost in stockout_cost_grid:\n",
        "    sim_m = simulate_policy(y_true, yhat_model, on_hand0, z, sigma_model, h=holding_cost_per_unit, p=p_cost)\n",
        "    sim_b = simulate_policy(y_true, yhat_lag1,  on_hand0, z, sigma_lag1,  h=holding_cost_per_unit, p=p_cost)\n",
        "\n",
        "    rows.append({\n",
        "        \"stockout_cost_per_unit\": p_cost,\n",
        "        \"total_cost_model\": sim_m[\"total_cost\"],\n",
        "        \"total_cost_lag1\": sim_b[\"total_cost\"],\n",
        "        \"delta_model_minus_lag1\": sim_m[\"total_cost\"] - sim_b[\"total_cost\"],\n",
        "        \"holding_model\": sim_m[\"holding_cost\"],\n",
        "        \"holding_lag1\": sim_b[\"holding_cost\"],\n",
        "        \"stockout_model\": sim_m[\"stockout_cost\"],\n",
        "        \"stockout_lag1\": sim_b[\"stockout_cost\"],\n",
        "        \"lost_units_model\": sim_m[\"lost_units\"],\n",
        "        \"lost_units_lag1\": sim_b[\"lost_units\"],\n",
        "        \"fill_rate_model\": sim_m[\"fill_rate\"],\n",
        "        \"fill_rate_lag1\": sim_b[\"fill_rate\"],\n",
        "        \"service_model\": sim_m[\"service_level\"],\n",
        "        \"service_lag1\": sim_b[\"service_level\"],\n",
        "    })\n",
        "\n",
        "sens = pd.DataFrame(rows)\n",
        "print(sens[[\"stockout_cost_per_unit\",\"total_cost_model\",\"total_cost_lag1\",\"delta_model_minus_lag1\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGD7jI4ghI9z",
        "outputId": "1c070e8a-a6b8-4e2f-d337-dda70254437f"
      },
      "outputs": [],
      "source": [
        "# break-even: cuando delta pasa de negativo a positivo\n",
        "sens_sorted = sens.sort_values(\"stockout_cost_per_unit\").copy()\n",
        "sens_sorted[\"model_better\"] = sens_sorted[\"delta_model_minus_lag1\"] < 0\n",
        "\n",
        "print(\"Modelo mejor (True/False) por p_cost:\")\n",
        "print(sens_sorted[[\"stockout_cost_per_unit\",\"model_better\",\"delta_model_minus_lag1\"]])\n",
        "\n",
        "# primer punto donde deja de ser mejor (delta >= 0)\n",
        "bad = sens_sorted[sens_sorted[\"delta_model_minus_lag1\"] >= 0]\n",
        "if len(bad) == 0:\n",
        "    print(\"El modelo es mejor que lag1 en todo el rango probado.\")\n",
        "else:\n",
        "    p_break = bad.iloc[0][\"stockout_cost_per_unit\"]\n",
        "    print(\"Break-even aproximado: stockout_cost_per_unit ≈\", p_break)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "D9DoIC2qhWF9",
        "outputId": "90a517f0-4c1f-42a3-b842-1456d5f31373"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"total_cost_model\"], marker=\"o\", label=\"model_hurdle\")\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"total_cost_lag1\"], marker=\"o\", label=\"baseline_lag1\")\n",
        "plt.title(\"Sensibilidad: costo total vs penalización por stockout\")\n",
        "plt.xlabel(\"stockout_cost_per_unit\")\n",
        "plt.ylabel(\"costo total\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6xNmuYth6w4",
        "outputId": "90135e50-04fa-410b-debc-1ba2906c0262"
      },
      "outputs": [],
      "source": [
        "print('hola mundo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "XLkYrHvmEGxP",
        "outputId": "c307fe57-0518-41b1-817a-8a87fed1e8b8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"delta_model_minus_lag1\"], marker=\"o\")\n",
        "plt.axhline(0, linewidth=1)\n",
        "plt.title(\"Diferencia de costo: (modelo − lag1) vs penalización por stockout\")\n",
        "plt.xlabel(\"stockout_cost_per_unit\")\n",
        "plt.ylabel(\"delta costo\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "omAXptZjEaxE",
        "outputId": "b6071ad7-b72a-4705-b085-ff2b5c62b300"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"lost_units_model\"], marker=\"o\", label=\"lost_units model\")\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"lost_units_lag1\"], marker=\"o\", label=\"lost_units lag1\")\n",
        "plt.title(\"Lost units vs penalización por stockout (constante por política)\")\n",
        "plt.xlabel(\"stockout_cost_per_unit\")\n",
        "plt.ylabel(\"lost units\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"fill_rate_model\"], marker=\"o\", label=\"fill_rate model\")\n",
        "plt.plot(sens[\"stockout_cost_per_unit\"], sens[\"fill_rate_lag1\"], marker=\"o\", label=\"fill_rate lag1\")\n",
        "plt.title(\"Fill rate vs penalización por stockout (debe ser constante)\")\n",
        "plt.xlabel(\"stockout_cost_per_unit\")\n",
        "plt.ylabel(\"fill_rate\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIIo6Do6Ed4l",
        "outputId": "169c7fd8-7342-41b7-c52c-9c5c84d91db9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "OUT_DIR = \"intermediate_data\"\n",
        "\n",
        "train_df = pd.read_parquet(f\"{OUT_DIR}/train.parquet\")\n",
        "valid_df = pd.read_parquet(f\"{OUT_DIR}/valid.parquet\")\n",
        "test_df  = pd.read_parquet(f\"{OUT_DIR}/test_features.parquet\")\n",
        "\n",
        "with open(f\"{OUT_DIR}/meta.json\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "# Baseline simple: solo tiempo + IDs + lag1 (y opcional lag12)\n",
        "basic_cols = []\n",
        "for c in [\"date_block_num\", \"month\", \"year\", \"shop_id\", \"item_id\", \"cnt_lag_1\", \"cnt_lag_12\"]:\n",
        "    if c in train_df.columns:\n",
        "        basic_cols.append(c)\n",
        "\n",
        "X_train = train_df[basic_cols]\n",
        "y_train = train_df[\"y\"].astype(np.float32)\n",
        "\n",
        "X_valid = valid_df[basic_cols]\n",
        "y_valid = valid_df[\"y\"].astype(np.float32)\n",
        "\n",
        "X_test = test_df[basic_cols]\n",
        "\n",
        "cat_features = [c for c in [\"shop_id\", \"item_id\", \"month\", \"year\"] if c in basic_cols]\n",
        "\n",
        "baseline_lgbm = lgb.LGBMRegressor(\n",
        "    n_estimators=4000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=64,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "baseline_lgbm.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric=\"rmse\",\n",
        "    categorical_feature=cat_features,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=True)]\n",
        ")\n",
        "\n",
        "pred_valid = np.clip(baseline_lgbm.predict(X_valid).astype(np.float32), 0, 20)\n",
        "rmse = float(np.sqrt(np.mean((pred_valid - y_valid.values) ** 2)))\n",
        "print(\"RMSE valid (baseline_lgbm):\", rmse)\n",
        "print(\"Best iteration:\", baseline_lgbm.best_iteration_)\n",
        "\n",
        "pred_test = np.clip(baseline_lgbm.predict(X_test).astype(np.float32), 0, 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HeOtgU4JG5Sp",
        "outputId": "ff357583-2ab3-4d18-dd7c-b720a391d79a"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "\n",
        "OUT_DIR = \"intermediate_data\"\n",
        "\n",
        "train_df = pd.read_parquet(f\"{OUT_DIR}/train.parquet\")\n",
        "valid_df = pd.read_parquet(f\"{OUT_DIR}/valid.parquet\")\n",
        "test_X   = pd.read_parquet(f\"{OUT_DIR}/test_features.parquet\")\n",
        "\n",
        "with open(f\"{OUT_DIR}/meta.json\") as f:\n",
        "    meta = json.load(f)\n",
        "\n",
        "feature_cols = meta[\"feature_cols\"]\n",
        "\n",
        "# -----------------------\n",
        "# 1) Baseline LightGBM simple (time + IDs + lags básicos)\n",
        "# -----------------------\n",
        "basic_cols = []\n",
        "for c in [\"date_block_num\", \"month\", \"year\", \"shop_id\", \"item_id\", \"cnt_lag_1\", \"cnt_lag_12\"]:\n",
        "    if c in train_df.columns:\n",
        "        basic_cols.append(c)\n",
        "\n",
        "X_train_b = train_df[basic_cols]\n",
        "y_train = train_df[\"y\"].astype(np.float32)\n",
        "\n",
        "X_valid_b = valid_df[basic_cols]\n",
        "y_valid = valid_df[\"y\"].astype(np.float32)\n",
        "\n",
        "cat_features_b = [c for c in [\"shop_id\", \"item_id\", \"month\", \"year\"] if c in basic_cols]\n",
        "\n",
        "baseline_lgbm = lgb.LGBMRegressor(\n",
        "    n_estimators=4000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=64,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "baseline_lgbm.fit(\n",
        "    X_train_b, y_train,\n",
        "    eval_set=[(X_valid_b, y_valid)],\n",
        "    eval_metric=\"rmse\",\n",
        "    categorical_feature=cat_features_b,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=200, verbose=True)]\n",
        ")\n",
        "\n",
        "pred_valid_base = np.clip(baseline_lgbm.predict(X_valid_b).astype(np.float32), 0, 20)\n",
        "rmse_base = float(np.sqrt(np.mean((pred_valid_base - y_valid.values) ** 2)))\n",
        "print(\"RMSE valid (baseline_lgbm):\", rmse_base)\n",
        "print(\"Best iteration baseline:\", baseline_lgbm.best_iteration_)\n",
        "\n",
        "# Guardar baseline\n",
        "joblib.dump(\n",
        "    {\"model\": baseline_lgbm, \"basic_cols\": basic_cols, \"cat_features\": cat_features_b, \"meta\": meta},\n",
        "    \"baseline_lgbm.pkl\"\n",
        ")\n",
        "print(\"Guardado: baseline_lgbm.pkl\")\n",
        "\n",
        "# -----------------------\n",
        "# 2) Cargar modelo principal (hurdle) y predecir en valid\n",
        "# -----------------------\n",
        "bundle = joblib.load(\"model_tarea1.pkl\")\n",
        "clf = bundle[\"clf\"]\n",
        "reg = bundle[\"reg\"]\n",
        "feat_h = bundle[\"feature_cols\"]\n",
        "\n",
        "X_valid_h = valid_df[feat_h]\n",
        "\n",
        "p_valid = clf.predict_proba(X_valid_h)[:, 1].astype(np.float32)\n",
        "mu_valid = reg.predict(X_valid_h).astype(np.float32)\n",
        "pred_valid_hurdle = np.clip(p_valid * mu_valid, 0, 20)\n",
        "\n",
        "rmse_hurdle = float(np.sqrt(np.mean((pred_valid_hurdle - y_valid.values) ** 2)))\n",
        "print(\"RMSE valid (model_hurdle):\", rmse_hurdle)\n",
        "\n",
        "# -----------------------\n",
        "# Helpers para gráficas\n",
        "# -----------------------\n",
        "def plot_calibration_by_decile(y_true, y_pred, title):\n",
        "    df = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred}).dropna()\n",
        "    df[\"decile\"] = pd.qcut(df[\"yhat\"], 10, duplicates=\"drop\")\n",
        "    rep = df.groupby(\"decile\").agg(y_mean=(\"y\",\"mean\"), yhat_mean=(\"yhat\",\"mean\")).reset_index()\n",
        "\n",
        "    x = np.arange(len(rep))\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(x, rep[\"yhat_mean\"], marker=\"o\", label=\"Predicho (mean)\")\n",
        "    plt.plot(x, rep[\"y_mean\"], marker=\"o\", label=\"Real (mean)\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Decil (0=ŷ más bajo, último=ŷ más alto)\")\n",
        "    plt.ylabel(\"Promedio\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_tail_underestimation(y_true, y_pred, title):\n",
        "    df = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred}).dropna()\n",
        "\n",
        "    thresholds = [0, 5, 10, 15]\n",
        "    rows = []\n",
        "    for thr in thresholds:\n",
        "        sub = df[df[\"y\"] >= thr]\n",
        "        rows.append((thr, len(sub), sub[\"y\"].mean(), sub[\"yhat\"].mean()))\n",
        "    rep = pd.DataFrame(rows, columns=[\"thr\", \"n\", \"mean_y\", \"mean_yhat\"])\n",
        "\n",
        "    x = np.arange(len(rep))\n",
        "    w = 0.35\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.bar(x - w/2, rep[\"mean_y\"], width=w, label=\"Real (mean)\")\n",
        "    plt.bar(x + w/2, rep[\"mean_yhat\"], width=w, label=\"Predicho (mean)\")\n",
        "    plt.title(title)\n",
        "    plt.xticks(x, [f\"y≥{t}\\n(n={n})\" for t,n in zip(rep[\"thr\"], rep[\"n\"])])\n",
        "    plt.ylabel(\"Promedio\")\n",
        "    plt.grid(True, axis=\"y\", alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_scatter_high(y_true, y_pred, thr, title):\n",
        "    df = pd.DataFrame({\"y\": y_true, \"yhat\": y_pred}).dropna()\n",
        "    df = df[df[\"y\"] >= thr]\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(df[\"y\"], df[\"yhat\"], s=6, alpha=0.2)\n",
        "    mx = max(df[\"y\"].max() if len(df) else 20, 20)\n",
        "    plt.plot([0, mx], [0, mx], linewidth=1)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"y real\")\n",
        "    plt.ylabel(\"y predicho\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_residuals(y_true, y_pred, title_prefix):\n",
        "    res = y_true - y_pred\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.hist(res, bins=80)\n",
        "    plt.title(f\"{title_prefix} | Histograma de residuales (y−ŷ)\")\n",
        "    plt.xlabel(\"y − ŷ\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.scatter(y_pred, res, s=6, alpha=0.2)\n",
        "    plt.axhline(0, linewidth=1)\n",
        "    plt.title(f\"{title_prefix} | Residual vs ŷ\")\n",
        "    plt.xlabel(\"ŷ\")\n",
        "    plt.ylabel(\"y − ŷ\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -----------------------\n",
        "# 3) Gráficas comparativas\n",
        "# -----------------------\n",
        "print(\"Comparación RMSE (validación)\")\n",
        "print(\"baseline_lgbm:\", rmse_base)\n",
        "print(\"modelo tarea 1:\", rmse_hurdle)\n",
        "\n",
        "plot_calibration_by_decile(y_valid.values, pred_valid_base, \"Baseline LGBM | Calibración por deciles\")\n",
        "plot_calibration_by_decile(y_valid.values, pred_valid_hurdle, \"modelotarea1 | Calibración por deciles\")\n",
        "\n",
        "plot_tail_underestimation(y_valid.values, pred_valid_base, \"Baseline LGBM | Subestimación en cola (por umbral)\")\n",
        "plot_tail_underestimation(y_valid.values, pred_valid_hurdle, \"modelotarea1 | Subestimación en cola (por umbral)\")\n",
        "\n",
        "plot_scatter_high(y_valid.values, pred_valid_base, 5, \"Baseline LGBM | y real vs y predicho (solo y≥5)\")\n",
        "plot_scatter_high(y_valid.values, pred_valid_hurdle, 5, \"modelotarea1 | y real vs y predicho (solo y≥5)\")\n",
        "\n",
        "plot_residuals(y_valid.values, pred_valid_base, \"Baseline LGBM\")\n",
        "plot_residuals(y_valid.values, pred_valid_hurdle, \"modelotarea1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U4o5YUBISlw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
